{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "25cbca1e",
      "metadata": {},
      "source": [
        "# La procrastination est-elle optimale ?\n",
        "\n",
        "Ce sujet est proposé par Pierre Matalon. Vous pouvez adresser vos questions ou remarques à pierre.matalon@polytechnique.edu.\n",
        "\n",
        "> \"Several studies have linked procrastination to individual performance, with the procrastinator performing more poorly overall, and to individual well-being, with the procrastinator being more miserable in the long term. For example, a survey indicated that procrastinating on taxes costs people on average $400 because of rushing and consequent errors, resulting in over $473 million in overpayments in 2002.\"\n",
        "\n",
        "*The Nature of Procrastination: A Meta-Analytic and Theoretical Review of Quintessential Self-Regulatory Failure*, P. Steel, Psychological Bulletin, 2007.\n",
        "\n",
        "L'idée de ce projet est de considérer les stratégies de répartition de la quantitié de travail dans le temps comme un problème de décision dynamique. \n",
        "A chaque instant, on choisit quelle quantité de travail fournir en essayant d'optimiser la conjonction d'effets opposés : la charge de travail restante diminue avec l'effort, mais la fatigue (et autres désagréments...) augmente.\n",
        "On parle de procrastination lorsque l'essentiel du travail à faire est repoussé à la fin de l'horizon temporel admissible. \n",
        "L'objectif est de faire apparaître la procrastination comme stratégie *optimale* dans un tel problème, et ainsi montrer qu'il s'agit en fait d'un comportement rationnel qui émerge spontanément de l'optimisation d'une fonction de coût.\n",
        "\n",
        "## Modélisation\n",
        "\n",
        "Un devoir, correspondant à une charge de travail fixée $x_0>0$, doit être rendu à la date $T>0$. (Notez que ce n'est pas un devoir de mathématiques, sinon nous ne saurions envisager la procrastination.)\n",
        "A chaque instant, l'étudiant choisit quelle quantité d'effort $u(t)$ fournir en fonction de la charge de travail restante $x(t)$ et de son état de fatigue $y(t)$.\n",
        "Par simplicité, la variable $y(t)$ modélise sous une variable unique tous les effets négatifs liés à l'effort de travail (fatigue cognitive, aversion, etc.).\n",
        "\n",
        "Nous avons donc deux variables d'état ($x$ et $y$) et une variable de contrôle ($u$).\n",
        "Le travail $x$ est une fonction décroissante du temps: $x\\in L^1([0,T])$ avec pour tout $t$, $x(t) \\leq x_0$.\n",
        "La fatigue $y\\in L^1([0,T])$ démarre avec une fatigue initiale $y_0\\geq 0$. \n",
        "En considérant que les capacités cérébrales sont bornées, l'effort $u\\in L^\\infty([0,T])$ prend ses valeurs dans l'intervalle admissible $[0,M]$, avec $M>0$.\n",
        "\n",
        "Nous considérons que le système dynamique est gouverné par les équations différentielles suivantes :\n",
        "\n",
        "$$\n",
        "\\begin{cases}\n",
        "\\dot{x}(t) = -u(t),                                      \\\\\n",
        "\\dot{y}(t) = \\beta u(t) - \\delta (1-\\frac{u(t)}{M}) y(t),\n",
        "\\end{cases}\n",
        "$$\n",
        "avec les conditions initiales\n",
        "$$\n",
        "x(0) = x_0, \\qquad y(0) = y_0.\n",
        "$$\n",
        "\n",
        "La première équation indique que le travail restant diminue proportionnellement à l'effort.\n",
        "On notera donc que la tâche n'est faisable dans le temps imparti que si $x_0 \\leq MT$.\n",
        "Dans la seconde équation, le terme $\\beta u(t)$ indique que fournir un effort augmente la fatigue, dont la quantité est convertie via un facteur constant $\\beta \\geq 0$.\n",
        "Le second terme modélise un phénomène de récupération naturelle.\n",
        "Plus l'effort est faible, plus on récupère, jusqu'à un maximum de $\\delta y(t)$ en l'absence d'effort. $\\delta \\geq 0$ est le coefficient d'efficacité de la récupération. Notons que plus la fatigue est élevée, plus la récupération naturelle est efficace, et que la récupération est nulle lorsque l'effort est maximal.\n",
        "\n",
        "La fonction de coût à minimiser est la suivante :\n",
        "\n",
        "$$\n",
        "J(u) = \\int_0^T e^{-\\rho t}\\big(D(u(t)) + E(y(t))\\big)\\,dt + \\Phi(x(T)),\n",
        "$$\n",
        "où\n",
        "- $D(u(t))$ mesure le désagrément immédiat de l'effort.\n",
        "- $E(y(t))$ mesure le coût de la fatigue.\n",
        "- Le terme d'actualisation $e^{-\\rho t}$, avec $\\rho\\geq 0$, reflète la préférence pour le présent, en faisant en sorte que les coûts immédiats comptent plus que les coûts futurs.\n",
        "- $\\Phi(x(T))$ pénalise le travail non terminé à la date limite.\n",
        "\n",
        "$D$, $E$ et $\\Phi$ sont des fonctions positives et croissantes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9d3e0c4",
      "metadata": {},
      "source": [
        "## Travail à réaliser\n",
        "\n",
        "### Question 1 : analyse\n",
        "Appliquez le principe du minimum de Pontryagin (PMP) à ce problème pour exhiber l'EDO à quatre inconnues à résoudre et le Hamiltonien à minimiser.\n",
        "Montrez que si $D$ est strictement convexe, alors le contrôle optimal est unique."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54541a7a",
      "metadata": {},
      "source": [
        "### Question 2 : résolution numérique\n",
        "\n",
        "On pose \n",
        "$$\n",
        "D(u) = \\frac{\\kappa}{2} u^2, \\qquad E(y) = \\frac{\\gamma}{2} y^2, \\qquad \\Phi(x) = \\frac{\\mu}{2} x^2.\n",
        "$$\n",
        "où $\\kappa$, $\\gamma$, $\\mu$ sont des paramètres constants et positifs.\n",
        "\n",
        "Implémentez la résolution numérique du problème.\n",
        "Seules les librairies `numpy` et `scipy` sont autorisées pour les calculs.\n",
        "\n",
        "Dans un premier temps, on considérera abstraites les fonctions $D$, $E$ et $\\Phi$ dans le code de résolution. \n",
        "On utilisera donc un algorithme numérique pour minimiser le Hamiltonien (la fonction `minimize_scalar` de `scipy` par exemple).\n",
        "On pourra ensuite spécialiser le code pour le choix quadratique de la fonction $D$ afin d'accélérer les calculs.\n",
        "\n",
        "Pour la résolution de l'équation différentielle ordinaire (EDO) à quatre inconnues issue du (PMP), \n",
        "on utilisera la fonction `solve_ivp` de `scipy`.\n",
        "\n",
        "Comme les états adjoints se résolvent en condition finale, implémenter une méthode de tir sera nécessaire pour déterminer leurs valeurs initiales.\n",
        "La méthode fonctionne de la façon suivante : on considère l'équation générale\n",
        "$$\n",
        "    \\dot{z}(t) = f(t,z)\n",
        "$$\n",
        "\n",
        "avec condition finale \n",
        "$$\n",
        "z(T) = \\alpha,\n",
        "$$\n",
        "où $\\alpha$ est donné.\n",
        "Pour tout $\\theta$, on note $z_\\theta$ la solution du problème de Cauchy composé de l'équation $\\dot{z}(t) = f(t,z)$ et de la condition initiale $z(0) = \\theta$.\n",
        "Soit la fonction $R$ définie par $R(\\theta) = z_\\theta(T)-\\alpha$ (c'est-à-dire le résidu sur la condition finale). \n",
        "On cherche donc $\\theta^*$ telle que $R(\\theta^*) = 0$.\n",
        "Un algorithme \"de type\" Newton pour la recherche de racine sera utilisé.\n",
        "On pourra notamment appeler la fonction `root` de `scipy`.\n",
        "L'appellation \"méthode de tir\" vient du caractère itératif de ces algorithmes : \n",
        "à partir d'une première valeur arbitraire $\\theta_0$ de la condition initiale, le résidu $z_{\\theta_0}(T)-\\alpha$ sur la condition finale est calculé, puis le \"tir\" est réajusté avec une nouvelle valeur $\\theta_1$, et ce jusqu'à convergence.\n",
        "\n",
        "Une fois les conditions initiales des états adjoints calculées, l'EDO est intégrée. \n",
        "Pour finir, le contrôle optimal est recalculé en post-processing, à partir des états optimaux.\n",
        "\n",
        "Affichez les graphes des variables d'état, de contrôle, et des états adjoints en fonction du temps, pour la solution optimale.\n",
        "Vérifiez que la procrastination apparaît comme stratégie optimale avec la configuration suivante :\n",
        "le problème est défini par les valeurs $T=3, x_0=100, y_0=0, M=70$, \n",
        "les équations d'évolution par $\\beta = 0.8, \\delta = 0.2$,\n",
        " et la fonction de coût par $\\rho = 1, \\kappa=1, \\gamma=1, \\mu=50$.\n",
        "\n",
        "### Résolution numérique"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6564a04b",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize_scalar, least_squares, root\n",
        "from scipy.integrate import solve_ivp\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46182c50",
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Parameters ---\n",
        "T     = 3   # final time\n",
        "x0    = 100 # total workload\n",
        "y0    = 0   # initial fatigue\n",
        "M     = 70  # maximum effort\n",
        "\n",
        "beta  = 0.8 # fatigue factor (how much fatigue increases with effort)\n",
        "delta = 0.2 # recovery factor (how much fatigue diminishes with time in the absence of effort)\n",
        "\n",
        "rho   =  1  # actualization factor (preference for the present over the future)\n",
        "kappa =  1  # weight of the control cost\n",
        "gamma =  1  # weight of the fatigue cost\n",
        "mu    = 50 # weight of the final workload cost\n",
        "\n",
        "# --- D ---\n",
        "def D(u):\n",
        "    raise RuntimeError(\"Unimplemented\")\n",
        "\n",
        "# --- E and E' ---\n",
        "def E(y):\n",
        "    raise RuntimeError(\"Unimplemented\")\n",
        "\n",
        "def diffE(y):\n",
        "    raise RuntimeError(\"Unimplemented\")\n",
        "\n",
        "# --- Phi and Phi' ---\n",
        "def Phi(x):\n",
        "    raise RuntimeError(\"Unimplemented\")\n",
        "\n",
        "def diffPhi(x):\n",
        "    raise RuntimeError(\"Unimplemented\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c40c4aa",
      "metadata": {},
      "source": [
        "Implémentez dans la cellule ci-dessous l'EDO à quatre inconnues issue du (PMP) en utilisant le contrôle optimal :\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bb1f8cd",
      "metadata": {},
      "outputs": [],
      "source": [
        "def minimize_H(t, x, y, px, py):\n",
        "    # Implement the minimization of H the Hamiltonian with respect to u at time t, given (x, y, px, py).\n",
        "    raise RuntimeError(\"Unimplemented\")\n",
        "\n",
        "def EDO(t, z):\n",
        "    x  = z[0]\n",
        "    y  = z[1]\n",
        "    px = z[2]\n",
        "    py = z[3]\n",
        "\n",
        "    # Implement the EDO using the optimal control\n",
        "    raise RuntimeError(\"Unimplemented\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18d37c68",
      "metadata": {},
      "outputs": [],
      "source": [
        "n_time_steps = 100\n",
        "def integrate_ODE(px0, py0):\n",
        "    \"\"\" Integrate the ODE system forward in time. \"\"\"\n",
        "    sol = solve_ivp(EDO, [0, T], [x0, y0, px0, py0], t_eval=np.linspace(0, T, n_time_steps), rtol=1e-9, atol=1e-10)\n",
        "    return sol.t, sol.y[0], sol.y[1], sol.y[2], sol.y[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e66dd38",
      "metadata": {},
      "source": [
        "### Méthode de tir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cf53e25",
      "metadata": {},
      "outputs": [],
      "source": [
        "def shooting_residual(p0):\n",
        "    \"\"\" Compute the residual for the shooting method. \"\"\"\n",
        "    [t, x, y, px, py] = integrate_ODE(p0[0], p0[1])\n",
        "\n",
        "    res_px = # implement the residual for px\n",
        "    res_py = # implement the residual for py\n",
        "    raise RuntimeError(\"Unimplemented\")\n",
        "\n",
        "    return np.array([res_px, res_py])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43a8e14f",
      "metadata": {},
      "outputs": [],
      "source": [
        "theta0 = np.array([0, 0])\n",
        "result = root(shooting_residual, theta0, method='broyden1', options={'disp': True, 'maxiter':1000})\n",
        "\n",
        "px0, py0 = result.x[0], result.x[1]\n",
        "\n",
        "if not result.success:\n",
        "    raise RuntimeError(\"The shooting method failed: \" + result.message)\n",
        "\n",
        "print(\"Final residual norm: \", np.linalg.norm(shooting_residual([px0, py0])))\n",
        "print(\"Optimal initial adjoints: px0 = \", px0, \", py0 = \", py0)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1a6c711",
      "metadata": {},
      "source": [
        "### Intégration du système\n",
        "\n",
        "Une fois les conditions initiales des états adjoints déterminées, réintégréz le système, recalculez le contrôle optimal à chaque instant, puis calculez le coût instantané de la solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72affae0",
      "metadata": {},
      "outputs": [],
      "source": [
        "t, x, y, px, py = ... # integrate the ODE to get the optimal trajectory\n",
        "\n",
        "u = ... # compute the optimal control u over time\n",
        "\n",
        "# Compute instantaneous cost function over time\n",
        "effort_cost = ...\n",
        "fatigue_cost = ...\n",
        "unfinished_workload_cost = ...\n",
        "total_cost = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73ba10e0",
      "metadata": {},
      "source": [
        "### Affichage des résultats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0d503bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot the results\n",
        "plt.figure(figsize=(18, 6))\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(t, x, label='$x(t)$', linewidth=2)\n",
        "plt.plot(t, y, label='$y(t)$', linewidth=2)\n",
        "plt.plot(t, u, label='$u(t)$', linewidth=2)\n",
        "plt.xlabel('t')\n",
        "plt.title('Variables d\\'état et contrôle')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(t, px, label='$p_x(t)$', linewidth=2)\n",
        "plt.plot(t, py, label='$p_y(t)$', linewidth=2)\n",
        "plt.xlabel('t')\n",
        "plt.title('Etats adjoints')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(t, effort_cost, label='coût d\\'effort', linewidth=2, color='red')\n",
        "plt.plot(t, fatigue_cost, label='coût de fatigue', linewidth=2, color='orange')\n",
        "plt.plot(t, total_cost, label='coût total', linewidth=2, color='blue')\n",
        "plt.xlabel('t')\n",
        "plt.title('Coût instantané')\n",
        "plt.grid()\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d111cab1",
      "metadata": {},
      "source": [
        "### Question 3\n",
        "Que mesurent les états adjoints dans ce problème ? Interpréter leurs courbes d'évolution dans la solution optimale."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c034ac84",
      "metadata": {},
      "source": [
        "### Question 4\n",
        "Le paramètre $\\rho$ simule l'aspect psychologique lié à la préférence naturelle pour le présent. \n",
        "Passez-le à 0, et constatez que la stratégie optimale est toujours de travailler au maximum à la fin, même si dans une moindre mesure. \n",
        "En déduire que $\\rho$ n'est pas le seul facteur poussant à la procrastination.\n",
        "Quels sont alors les paramètres sur lesquels vous pouvez jouer pour obtenir une répartition plus équilibrée de l'effort ?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42804532",
      "metadata": {},
      "source": [
        "### Question 5\n",
        "Reprenez le paramétrage de la question 2 et remplacez $D$ par la fonction $D(u) = \\kappa u$. Que pouvez-vous dire sur le contrôle optimal ? Que constatez-vous concernant l'efficacité de la méthode de tir ? Expliquez."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb82f4ad",
      "metadata": {},
      "source": [
        "### Question 6 (bonus)\n",
        "\n",
        "Afin de parvenir à résoudre le problème dans ce cas difficile, implémentez la méthode d'homotopie suivante.\n",
        "Pour $\\epsilon \\in [0,1]$, on pose \n",
        "$$\n",
        "D_\\varepsilon(u) = \\kappa \\left( (1-\\varepsilon) u + \\varepsilon \\frac{1}{2}u^2 \\right) .\n",
        "$$\n",
        "L'idée est de résoudre le problème pour $\\varepsilon = 1$ (cas quadratique), puis de diminuer progressivement $\\varepsilon$, en utilisant à chaque étape la solution précédente comme condition initiale pour la méthode de tir.\n",
        "Lorsque la fonction `root` ne parvient pas à converger, diminuez la taille du pas sur $\\varepsilon$ et recommencez.\n",
        "Notez qu'il sera difficile d'atteindre un $\\varepsilon$ très bas, donc arrêtez lorsque `root` ne converge plus même pour des pas très petits."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "python_notebook",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
